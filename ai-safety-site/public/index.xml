<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Safety Papers</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on AI Safety Papers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Oct 2024 13:17:18 +0200</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My First Post</title>
      <link>http://localhost:1313/en/posts/my_first_post/</link>
      <pubDate>Sun, 20 Oct 2024 13:17:18 +0200</pubDate>
      
      <guid>http://localhost:1313/en/posts/my_first_post/</guid>
      <description>&lt;p&gt;sdasd&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>http://localhost:1313/posts/my_first_post/</link>
      <pubDate>Sun, 20 Oct 2024 13:17:18 +0200</pubDate>
      
      <guid>http://localhost:1313/posts/my_first_post/</guid>
      <description>&lt;p&gt;sdasd&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AI Alignment: A Comprehensive Overview</title>
      <link>http://localhost:1313/en/posts/my_second_post/sample-paper-1/</link>
      <pubDate>Sat, 15 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/en/posts/my_second_post/sample-paper-1/</guid>
      <description>&lt;p&gt;Content of the paper&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AI Alignment: A Comprehensive Overview</title>
      <link>http://localhost:1313/posts/my_second_post/sample-paper-1/</link>
      <pubDate>Sat, 15 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/my_second_post/sample-paper-1/</guid>
      <description>&lt;p&gt;Content of the paper&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h1 id=&#34;about-ai-safety-papers&#34; class=&#34;header-anchor-wrapper&#34;&gt;About AI Safety Papers
  &lt;a href=&#34;#about-ai-safety-papers&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;Welcome to AI Safety Papers, a curated collection of the latest research in AI safety. Our mission is to make cutting-edge AI safety research more accessible to researchers, practitioners, and enthusiasts.&lt;/p&gt;

&lt;h2 id=&#34;what-we-do&#34; class=&#34;header-anchor-wrapper&#34;&gt;What We Do
  &lt;a href=&#34;#what-we-do&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;We aggregate recent papers from various sources, including arXiv and Semantic Scholar.&lt;/li&gt;
&lt;li&gt;Our AI-powered system summarizes these papers to provide quick insights.&lt;/li&gt;
&lt;li&gt;We present these summaries along with links to the original papers for easy access.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;why-ai-safety&#34; class=&#34;header-anchor-wrapper&#34;&gt;Why AI Safety?
  &lt;a href=&#34;#why-ai-safety&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h2&gt;

&lt;p&gt;As artificial intelligence continues to advance rapidly, ensuring its safe and beneficial development becomes increasingly crucial. AI safety research aims to address potential risks and challenges associated with AI systems, working towards creating AI that is aligned with human values and interests.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://localhost:1313/en/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/en/about/</guid>
      <description>&lt;h1 id=&#34;about-ai-safety-papers&#34; class=&#34;header-anchor-wrapper&#34;&gt;About AI Safety Papers
  &lt;a href=&#34;#about-ai-safety-papers&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;Welcome to AI Safety Papers, a curated collection of the latest research in AI safety. Our mission is to make cutting-edge AI safety research more accessible to researchers, practitioners, and enthusiasts.&lt;/p&gt;

&lt;h2 id=&#34;what-we-do&#34; class=&#34;header-anchor-wrapper&#34;&gt;What We Do
  &lt;a href=&#34;#what-we-do&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;We aggregate recent papers from various sources, including arXiv and Semantic Scholar.&lt;/li&gt;
&lt;li&gt;Our AI-powered system summarizes these papers to provide quick insights.&lt;/li&gt;
&lt;li&gt;We present these summaries along with links to the original papers for easy access.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;why-ai-safety&#34; class=&#34;header-anchor-wrapper&#34;&gt;Why AI Safety?
  &lt;a href=&#34;#why-ai-safety&#34; class=&#34;header-anchor-link&#34;&gt;
    &lt;svg width=&#34;16px&#34; height=&#34;16px&#34; viewBox=&#34;0 0 24 24&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/svg&gt;
  &lt;/a&gt;
&lt;/h2&gt;

&lt;p&gt;As artificial intelligence continues to advance rapidly, ensuring its safe and beneficial development becomes increasingly crucial. AI safety research aims to address potential risks and challenges associated with AI systems, working towards creating AI that is aligned with human values and interests.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>