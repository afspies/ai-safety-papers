import sys
import os

# Add the project root to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from src.models.article import Article


# Test paper:
# Exploring Protein-DNA Binding Residue Prediction and Consistent Interpretability Analysis Using Deep Learning	14/10/2024	Interestingly, the results show that large-scale pre-trained protein language models, together with attention mechanisms, can effectively capture structural information solely from protein sequence inputs.	https://www.biorxiv.org/content/biorxiv/early/2024/10/14/2024.10.12.613667.full.pdf	Yufan Liu	Accurately identifying DNA-binding residues is a crucial step in developing computational tools to model DNA-protein binding properties, which is essential for binding pocket discovery and related drug design. Although several tools have been developed to predict DNA-binding residues based on protein sequences and structures, their performance remains limited, and proteins with crystal structures still represent only a small fraction of DNA-binding proteins. Additionally, the process of extracting handcrafted features for protein representation is labor-intensive. In this study, we combined the strengths of pre-trained protein language models and attention mechanisms to propose a sequence-based method: an attention-based deep learning approach for accurately predicting DNA-binding residues, incorporating a contrastive learning module. Our method outperformed all other sequence-based models across two prevalent benchmark datasets. Furthermore, we developed a structure-based graph neural network (GNN) model to demonstrate the impact of the contrastive module. A common limitation of existing models is their lack of interpretability, which hinders our ability to understand what these models have learned. To address this, we introduced a novel perspective for interpreting our sequence-based model by analyzing the consistency between attention scores and the edge weights generated by the GNN model. Interestingly, our results show that large-scale pre-trained protein language models, together with attention mechanisms, can effectively capture structural information solely from protein sequence inputs.	bioRxiv	FALSE	FALSE		2024	6e640f9a2de1e8afc89515047b7f341d1f206cb6	0	1	specter_v1	
# Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization	16/10/2024	This work investigates how mechanistic interpretability -- which, in part, aims to identify model components associated to specific interpretable mechanisms that make up a model capability -- can improve the precision and effectiveness of editing and unlearning.	https://www.semanticscholar.org/paper/23a921483746b8b3c828bd601f54d485bec32014	P. Guo, Aaquib Syed, Abhay Sheshadri, Aidan Ewart, G. Dziugaite	Methods for knowledge editing and unlearning in large language models seek to edit or remove undesirable knowledge or capabilities without compromising general language modeling performance. This work investigates how mechanistic interpretability -- which, in part, aims to identify model components (circuits) associated to specific interpretable mechanisms that make up a model capability -- can improve the precision and effectiveness of editing and unlearning. We find a stark difference in unlearning and edit robustness when training components localized by different methods. We highlight an important distinction between methods that localize components based primarily on preserving outputs, and those finding high level mechanisms with predictable intermediate states. In particular, localizing edits/unlearning to components associated with the lookup-table mechanism for factual recall 1) leads to more robust edits/unlearning across different input/output formats, and 2) resists attempts to relearn the unwanted information, while also reducing unintended side effects compared to baselines, on both a sports facts dataset and the CounterFact dataset across multiple models. We also find that certain localized edits disrupt the latent knowledge in the model more than any other baselines, making unlearning more robust to various attacks.		FALSE	FALSE		2024	23a921483746b8b3c828bd601f54d485bec32014	0	1	specter_v1										

def test_article_creation():
    # Example entry data
    uid = "6e640f9a2de1e8afc89515047b7f341d1f206cb6"
    title = "Exploring Protein-DNA Binding Residue Prediction and Consistent Interpretability Analysis Using Deep Learning"
    url = "https://www.biorxiv.org/content/biorxiv/early/2024/10/14/2024.10.12.613667.full.pdf"  # Replace with the actual URL of the PDF

    # Create an Article instance
    article = Article(uid, title, url)

    # Download the PDF
    try:
        article.download_pdf()
        print(f"PDF downloaded successfully for article: {title}")
    except Exception as e:
        print(f"Failed to download PDF: {e}")

    # Create a thumbnail
    try:
        thumbnail_path = article.create_thumbnail()
        print(f"Thumbnail created at: {thumbnail_path}")
    except Exception as e:
        print(f"Failed to create thumbnail: {e}")

if __name__ == "__main__":
    test_article_creation()
